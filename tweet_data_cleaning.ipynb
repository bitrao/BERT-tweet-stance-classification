{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TWEET STANCE CLASSIFIER\n",
    "### (Data Preparation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nguyennguyen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nguyennguyen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from charset_normalizer import detect\n",
    "from utils.data_processor import preprocess_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/StanceDataset/train.csv'\n",
    "test_dir = 'data/StanceDataset/test.csv'\n",
    "ind_test_dir = 'data/kawintiranon-stance-detection/biden_stance_test_public.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided csv for the dataset contain several unsupported *characters*, we skipped those and load the usable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from charset_normalizer import detect\n",
    "# Detect the encoding\n",
    "with open(train_dir, \"rb\") as f:\n",
    "    detected_encoding = detect(f.read())[\"encoding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_dir, encoding=detected_encoding, engine='python', on_bad_lines='skip')\n",
    "test_df = pd.read_csv(test_dir, encoding=detected_encoding, engine='python', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_test_df = pd.read_csv(ind_test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       @tedcruz And, #HandOverTheServer she wiped cle...\n",
       "1       Hillary is our best choice if we truly want to...\n",
       "2       @TheView I think our country is ready for a fe...\n",
       "3       I just gave an unhealthy amount of my hard-ear...\n",
       "4       @PortiaABoulger Thank you for adding me to you...\n",
       "                              ...                        \n",
       "2909    There's a law protecting unborn eagles, but no...\n",
       "2910    I am 1 in 3... I have had an abortion #Abortio...\n",
       "2911    How dare you say my sexual preference is a cho...\n",
       "2912    Equal rights for those 'born that way', no rig...\n",
       "2913    #POTUS seals his legacy w/ 1/2 doz wins. The #...\n",
       "Name: Tweet, Length: 2914, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Tweet'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Tweet']  = train_df['Tweet'].apply(preprocess_tweet)\n",
    "test_df['Tweet']  = test_df['Tweet'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_test_df.text = ind_test_df.text.apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('data/processed_train.csv')\n",
    "test_df.to_csv('data/processed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_test_df.rename(columns={\"text\": \"Tweet\", \"label\": \"Stance\"}).assign(Target=\"Joe Biden\").to_csv('data/processed_ind_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
